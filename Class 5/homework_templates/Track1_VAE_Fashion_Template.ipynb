{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Homework - Track 1: Fashion Design with VAE\n",
    "## Student Name: [Your Name]\n",
    "## Student ID: [Your ID]\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load and Preprocess Data (10 points)\n",
    "\n",
    "**TODO:** \n",
    "- Load Fashion MNIST dataset\n",
    "- Apply appropriate transformations\n",
    "- Create train and validation DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    # TODO: Add your transformations here\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load Fashion MNIST\n",
    "# TODO: Load training and test datasets\n",
    "\n",
    "# Create DataLoaders\n",
    "# TODO: Create train_loader and test_loader with appropriate batch size\n",
    "\n",
    "# Visualize some samples\n",
    "# TODO: Display a grid of sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define VAE Architecture (20 points)\n",
    "\n",
    "**TODO:**\n",
    "- Implement Encoder\n",
    "- Implement Decoder\n",
    "- Include reparameterization trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # TODO: Define encoder layers\n",
    "        # Hint: input is 28x28=784, output should be latent_dim\n",
    "        \n",
    "        # Latent space parameters\n",
    "        # TODO: Define fc_mu and fc_logvar\n",
    "        \n",
    "        # Decoder\n",
    "        # TODO: Define decoder layers\n",
    "        # Hint: input is latent_dim, output should be 784\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # TODO: Implement encoder forward pass\n",
    "        # Return mu and logvar\n",
    "        pass\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # TODO: Implement reparameterization trick\n",
    "        # z = mu + eps * std where eps ~ N(0,1)\n",
    "        pass\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # TODO: Implement decoder forward pass\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Complete forward pass\n",
    "        # Return reconstructed x, mu, and logvar\n",
    "        pass\n",
    "\n",
    "# Initialize model\n",
    "model = VAE(latent_dim=20).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Define Loss Function\n",
    "\n",
    "VAE loss = Reconstruction Loss + KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    TODO: Implement VAE loss\n",
    "    \n",
    "    Args:\n",
    "        recon_x: reconstructed images\n",
    "        x: original images\n",
    "        mu: mean of latent distribution\n",
    "        logvar: log variance of latent distribution\n",
    "    \n",
    "    Returns:\n",
    "        total_loss: reconstruction loss + KL divergence\n",
    "    \"\"\"\n",
    "    # Reconstruction loss (Binary Cross Entropy)\n",
    "    # TODO: Calculate reconstruction loss\n",
    "    \n",
    "    # KL Divergence\n",
    "    # TODO: Calculate KL divergence\n",
    "    # KLD = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
    "    \n",
    "    return None  # TODO: Return total loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Train the Model (20 points)\n",
    "\n",
    "**TODO:**\n",
    "- Train for at least 20 epochs\n",
    "- Monitor and plot losses\n",
    "- Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 20  # TODO: Adjust as needed\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # TODO: Implement training loop\n",
    "    # - Iterate through train_loader\n",
    "    # - Forward pass\n",
    "    # - Calculate loss\n",
    "    # - Backward pass\n",
    "    # - Update weights\n",
    "    \n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # TODO: Save checkpoint every 5 epochs\n",
    "\n",
    "# Plot training loss\n",
    "# TODO: Create loss plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Generate New Fashion Items (10 points)\n",
    "\n",
    "**TODO:**\n",
    "- Generate 50 new samples\n",
    "- Create visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO: Sample from latent space and generate images\n",
    "    # Create a grid of 50 samples (e.g., 5x10)\n",
    "    pass\n",
    "\n",
    "# Visualize generated samples\n",
    "# TODO: Display generated images in a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Latent Space Interpolation\n",
    "\n",
    "Create smooth transitions between fashion items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement latent space interpolation\n",
    "# - Sample two points in latent space\n",
    "# - Interpolate between them\n",
    "# - Generate images at each interpolation step\n",
    "# - Visualize the transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Analysis (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Quality Evaluation (10 points)\n",
    "\n",
    "**TODO:**\n",
    "- Compare original vs reconstructed images\n",
    "- Calculate quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction quality\n",
    "# TODO: Take test samples and reconstruct them\n",
    "# TODO: Display original and reconstructed side by side\n",
    "# TODO: Calculate MSE or other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Business Application (15 points)\n",
    "\n",
    "**Answer the following questions in markdown cells:**\n",
    "\n",
    "#### Q1: How could this VAE be used in fashion retail?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "#### Q2: Estimate cost savings vs manual design\n",
    "\n",
    "*Your analysis here*\n",
    "\n",
    "#### Q3: Identify 3 specific use cases\n",
    "\n",
    "1. *Use case 1*\n",
    "2. *Use case 2*\n",
    "3. *Use case 3*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Limitations (5 points)\n",
    "\n",
    "**Discuss model limitations and improvements:**\n",
    "\n",
    "*Your analysis here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Documentation\n",
    "\n",
    "### Summary\n",
    "\n",
    "*Write a brief summary of your work, results, and key findings*\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "*What would you do differently or improve?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] Generated 50+ sample images\n",
    "- [ ] Created latent space visualizations\n",
    "- [ ] Answered all business analysis questions\n",
    "- [ ] Included 2-page business report (separate PDF)\n",
    "- [ ] Commented code appropriately\n",
    "- [ ] Created README.txt with setup instructions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
