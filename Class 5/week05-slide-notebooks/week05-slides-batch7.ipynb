{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48bf8608",
   "metadata": {},
   "source": [
    "# Week05 Slides Batch7\n",
    "\n",
    "**Interactive Jupyter Notebook Version**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900d817",
   "metadata": {},
   "source": [
    "# Week 5: Wrap-up & Next Steps - Batch 7 (Slides 36-40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c900c",
   "metadata": {},
   "source": [
    "Deployment Best Practices\n",
    "\n",
    "### From Development to Production\n",
    "\n",
    "**Key Considerations:**\n",
    "\n",
    "**1. Infrastructure**\n",
    "- GPU requirements (A100, V100, T4)\n",
    "- Latency targets\n",
    "- Scalability needs\n",
    "- Cost optimization\n",
    "\n",
    "**2. Model Serving**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f90e2",
   "metadata": {},
   "source": [
    "**3. Monitoring**\n",
    "- Request latency\n",
    "- Generation quality\n",
    "- Cost per request\n",
    "- Error rates\n",
    "- User satisfaction\n",
    "\n",
    "**4. A/B Testing**\n",
    "- Compare AI vs traditional\n",
    "- Test different models\n",
    "- Optimize prompts\n",
    "- Measure business impact\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c070f",
   "metadata": {},
   "source": [
    "Ethics & Governance\n",
    "\n",
    "### Responsible AI Development\n",
    "\n",
    "**Key Ethical Considerations:**\n",
    "\n",
    "**1. Copyright & Ownership**\n",
    "- Training data rights\n",
    "- Generated content ownership\n",
    "- Attribution requirements\n",
    "- Fair use policies\n",
    "\n",
    "**2. Deepfakes & Misinformation**\n",
    "- Watermarking generated content\n",
    "- Detection systems\n",
    "- Disclosure requirements\n",
    "- Verification processes\n",
    "\n",
    "**3. Bias & Fairness**\n",
    "- Training data diversity\n",
    "- Output bias testing\n",
    "- Fair representation\n",
    "- Inclusive design\n",
    "\n",
    "**4. Privacy**\n",
    "- Data protection\n",
    "- Voice/likeness rights\n",
    "- User consent\n",
    "- Data retention policies\n",
    "\n",
    "**Best Practices:**\n",
    "âœ… Transparent AI usage disclosure\n",
    "âœ… Human-in-the-loop workflows\n",
    "âœ… Regular bias audits\n",
    "âœ… Clear terms of service\n",
    "âœ… User control over data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa99965",
   "metadata": {},
   "source": [
    "Week 5 Assignment\n",
    "\n",
    "### Hands-on Project: Build a GenAI Application\n",
    "\n",
    "**Project Options (Choose One):**\n",
    "\n",
    "**Option 1: Marketing Content Generator**\n",
    "- Build image generation pipeline\n",
    "- Generate 10 product images\n",
    "- Calculate ROI vs traditional methods\n",
    "- Present business case\n",
    "\n",
    "**Option 2: Audio Application**\n",
    "- Create TTS or music system\n",
    "- Generate 5 audio samples\n",
    "- Evaluate quality metrics\n",
    "- Propose business use case\n",
    "\n",
    "**Option 3: Multimodal System**\n",
    "- Combine image + audio generation\n",
    "- Create short video (15-30 seconds)\n",
    "- Document technical approach\n",
    "- Analyze cost-benefit\n",
    "\n",
    "**Deliverables:**\n",
    "1. Working code (GitHub repo)\n",
    "2. Generated samples\n",
    "3. Technical documentation\n",
    "4. Business case presentation (5 slides)\n",
    "5. ROI analysis\n",
    "\n",
    "**Due:** Week 6, Day 1  \n",
    "**Presentation:** Week 6, Day 2\n",
    "\n",
    "**Grading Criteria:**\n",
    "- Technical implementation (40%)\n",
    "- Quality of outputs (20%)\n",
    "- Business viability (20%)\n",
    "- Presentation (20%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbefaa3",
   "metadata": {},
   "source": [
    "Resources & Further Learning\n",
    "\n",
    "### Continue Your GenAI Journey\n",
    "\n",
    "**Online Courses:**\n",
    "- **Hugging Face Diffusion Models Course** (Free)\n",
    "- **Fast.ai Practical Deep Learning** (Free)\n",
    "- **DeepLearning.AI Generative AI Specialization**\n",
    "- **Stanford CS236: Deep Generative Models**\n",
    "\n",
    "**Tools & Platforms:**\n",
    "- **Hugging Face** - Models & datasets\n",
    "- **Replicate** - Easy model deployment\n",
    "- **RunwayML** - Creative AI tools\n",
    "- **Google Colab** - Free GPU notebooks\n",
    "\n",
    "**Research Papers:**\n",
    "- \"Denoising Diffusion Probabilistic Models\" (Ho et al., 2020)\n",
    "- \"WaveNet: A Generative Model for Raw Audio\" (van den Oord et al., 2016)\n",
    "- \"MuseNet\" (OpenAI, 2019)\n",
    "- \"MusicLM: Generating Music From Text\" (Google, 2023)\n",
    "\n",
    "**Communities:**\n",
    "- r/StableDiffusion\n",
    "- r/MachineLearning\n",
    "- Hugging Face Discord\n",
    "- AI Discord communities\n",
    "\n",
    "**Newsletters:**\n",
    "- The Batch (DeepLearning.AI)\n",
    "- Import AI\n",
    "- The Algorithm (MIT Technology Review)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3a537",
   "metadata": {},
   "source": [
    "Summary & Next Week Preview\n",
    "\n",
    "### Week 5 Recap\n",
    "\n",
    "**What We Covered:**\n",
    "\n",
    "**Images (Slides 1-15)**\n",
    "âœ… VAEs, GANs, Diffusion Models\n",
    "âœ… Stable Diffusion & ControlNet\n",
    "âœ… Image editing techniques\n",
    "âœ… Business applications\n",
    "\n",
    "**Audio & Music (Slides 16-25)**\n",
    "âœ… WaveNet architecture\n",
    "âœ… Text-to-speech systems\n",
    "âœ… Voice cloning\n",
    "âœ… Music generation (RNN, Transformers, MuseNet, MusicLM)\n",
    "âœ… Style transfer\n",
    "\n",
    "**Advanced Topics (Slides 26-30)**\n",
    "âœ… Multimodal generation\n",
    "âœ… Real-time optimization\n",
    "âœ… Quality metrics\n",
    "âœ… Deployment strategies\n",
    "\n",
    "**Business Applications (Slides 31-40)**\n",
    "âœ… Industry use cases\n",
    "âœ… ROI analysis\n",
    "âœ… Implementation roadmap\n",
    "âœ… Ethics & governance\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Diffusion models** are state-of-the-art for images\n",
    "2. **Audio generation** requires different techniques (WaveNet, Transformers)\n",
    "3. **Real-time applications** need optimization (distillation, quantization)\n",
    "4. **Business value** is substantial (90-99% cost reduction in many cases)\n",
    "5. **Ethics matter** - responsible AI is essential\n",
    "\n",
    "---\n",
    "\n",
    "**Next Week Preview: Week 6 - Large Language Models**\n",
    "\n",
    "Topics:\n",
    "- GPT architecture deep dive\n",
    "- Prompt engineering\n",
    "- Fine-tuning strategies\n",
    "- RAG (Retrieval Augmented Generation)\n",
    "- LangChain & agents\n",
    "- Building LLM applications\n",
    "\n",
    "**Preparation:**\n",
    "- Review transformer basics (Week 4)\n",
    "- Complete Week 5 assignment\n",
    "- Read: \"Attention Is All You Need\" paper\n",
    "- Experiment with ChatGPT API\n",
    "\n",
    "---\n",
    "\n",
    "**Thank You!**\n",
    "\n",
    "Questions? Office hours: TBD  \n",
    "Discussion forum: Canvas  \n",
    "Code examples: GitHub repo\n",
    "\n",
    "**See you next week! ðŸš€**\n",
    "\n",
    "---\n",
    "\n",
    "**End of Week 5**\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Quick Reference\n",
    "\n",
    "### API Costs (Approximate, 2026)\n",
    "\n",
    "| Service | Type | Cost |\n",
    "|---------|------|------|\n",
    "| Stable Diffusion API | Image | $0.01/image |\n",
    "| DALL-E 3 | Image | $0.04/image |\n",
    "| ElevenLabs TTS | Audio | $0.30/1000 chars |\n",
    "| Google Cloud TTS | Audio | $4/1M chars |\n",
    "| MusicGen | Music | $0.05/minute |\n",
    "\n",
    "### Model Sizes\n",
    "\n",
    "| Model | Parameters | VRAM | Speed |\n",
    "|-------|-----------|------|-------|\n",
    "| SD 1.5 | 860M | 4GB | 2s/image |\n",
    "| SDXL | 2.6B | 8GB | 5s/image |\n",
    "| SDXL Turbo | 2.6B | 8GB | 0.1s/image |\n",
    "| WaveNet | 100M+ | 2GB | 10s/second (audio) |\n",
    "| MusicLM | Multi-model | 16GB+ | 30s (30s audio) |\n",
    "\n",
    "### Useful Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbff55e",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Install key packages\n",
    "pip install diffusers transformers torch torchvision\n",
    "pip install librosa pretty_midi musicgen\n",
    "\n",
    "# Test GPU\n",
    "python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "\n",
    "# Run Stable Diffusion\n",
    "python -m diffusers.pipelines.stable_diffusion \\\n",
    "  --prompt \"a cat\" --output cat.png\n",
    "\n",
    "# Generate music\n",
    "python -m musicgen --prompt \"upbeat jazz\" --duration 30\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac69ae",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "**Out of Memory Error:**\n",
    "- Reduce batch size\n",
    "- Use smaller resolution\n",
    "- Enable gradient checkpointing\n",
    "- Use mixed precision (fp16)\n",
    "\n",
    "**Slow Generation:**\n",
    "- Use SDXL Turbo or distilled models\n",
    "- Reduce inference steps\n",
    "- Use GPU instead of CPU\n",
    "- Enable xformers for memory efficiency\n",
    "\n",
    "**Poor Quality:**\n",
    "- Improve prompts (be specific)\n",
    "- Increase inference steps\n",
    "- Use negative prompts\n",
    "- Try different models\n",
    "\n",
    "---\n",
    "\n",
    "**Course Repository:** https://github.com/appjr/GenAIForBusinessOnline  \n",
    "**Instructor:** Dr. [Name]  \n",
    "**TA Support:** [Email]  \n",
    "**Office Hours:** [Times]\n",
    "\n",
    "**Good luck with your projects! ðŸŽ¨ðŸŽµðŸ¤–**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
