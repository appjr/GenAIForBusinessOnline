{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39705333",
   "metadata": {},
   "source": [
    "# Gan Mnist\n",
    "\n",
    "**From Week 5 Code Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c017d76",
   "metadata": {},
   "source": [
    "GAN (Generative Adversarial Network) for MNIST\n",
    "From: week05-slides-batch1.md - Slide 4\n",
    "\n",
    "Complete GAN with Generator and Discriminator, adversarial training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe5ab0",
   "metadata": {},
   "source": [
    "    def __init__(self, latent_dim=100):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.model(z).view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    criterion = nn.BCELoss()\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            real_output = discriminator(real_images)\n",
    "            d_loss_real = criterion(real_output, real_labels)\n",
    "            \n",
    "            # Fake images\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images = generator(z)\n",
    "            fake_output = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(fake_output, fake_labels)\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images = generator(z)\n",
    "            fake_output = discriminator(fake_images)\n",
    "            g_loss = criterion(fake_output, real_labels)  # Want D to think they're real\n",
    "            \n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch [{epoch}/{epochs}] Batch [{batch_idx}/{len(dataloader)}] \n",
    "                      f'D_loss: {d_loss.item():.4f} G_loss: {g_loss.item():.4f}')\n",
    "        \n",
    "        # Save samples\n",
    "        if epoch % 10 == 0:\n",
    "            generator.eval()\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(64, latent_dim).to(device)\n",
    "                samples = generator(z).cpu()\n",
    "                \n",
    "                fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
    "                for i, ax in enumerate(axes.flat):\n",
    "                    ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                plt.suptitle(f'GAN Generated Samples - Epoch {epoch}', fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'gan_epoch_{epoch}.png', dpi=150)\n",
    "                plt.close()\n",
    "            generator.train()\n",
    "    \n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"GAN TRAINING ON MNIST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    \n",
    "    # Data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "    # Models\n",
    "    generator = Generator(latent_dim=100).to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    \n",
    "    print(f\"\\nGenerator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "    \n",
    "    # Train\n",
    "    generator, discriminator = train_gan(generator, discriminator, dataloader, epochs=50, device=device)\n",
    "    \n",
    "    print(\"\\nâœ“ GAN training complete! Check gan_epoch_*.png files\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
