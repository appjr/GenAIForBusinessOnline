{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c62c9",
   "metadata": {},
   "source": [
    "# Vae Mnist\n",
    "\n",
    "**From Week 5 Code Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0da53",
   "metadata": {},
   "source": [
    "VAE (Variational Autoencoder) for MNIST\n",
    "From: week05-slides-batch1.md - Slide 2\n",
    "\n",
    "Complete implementation of VAE with encoder, decoder, and reparameterization trick."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb502803",
   "metadata": {},
   "source": [
    "    \n",
    "    def __init__(self, latent_dim=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(200, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(200, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0249f88",
   "metadata": {},
   "source": [
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3897b",
   "metadata": {},
   "source": [
    "    # Reconstruction loss\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    \n",
    "    # KL divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train_vae(model, train_loader, epochs=10, lr=1e-3, device='cpu'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get test batch\n",
    "        data, _ = next(iter(test_loader))\n",
    "        data = data.to(device)\n",
    "        \n",
    "        # Reconstruct\n",
    "        recon, _, _ = model(data)\n",
    "        \n",
    "        # Plot\n",
    "        n = 8\n",
    "        fig, axes = plt.subplots(2, n, figsize=(12, 3))\n",
    "        for i in range(n):\n",
    "            # Original\n",
    "            axes[0, i].imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[0, i].axis('off')\n",
    "            if i == 0:\n",
    "                axes[0, i].set_title('Original', fontsize=10)\n",
    "            \n",
    "            # Reconstruction\n",
    "            axes[1, i].imshow(recon[i].cpu().view(28, 28), cmap='gray')\n",
    "            axes[1, i].axis('off')\n",
    "            if i == 0:\n",
    "                axes[1, i].set_title('Reconstructed', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('vae_reconstruction.png', dpi=150)\n",
    "        print(\"✓ Saved reconstruction to vae_reconstruction.png\")\n",
    "        \n",
    "        # Generate new samples\n",
    "        fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
    "        z = torch.randn(32, 20).to(device)\n",
    "        samples = model.decode(z)\n",
    "        \n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.imshow(samples[i].cpu().view(28, 28), cmap='gray')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle('Generated Samples from VAE', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('vae_generated.png', dpi=150)\n",
    "        print(\"✓ Saved generated samples to vae_generated.png\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"VAE TRAINING ON MNIST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    \n",
    "    # Data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    model = VAE(latent_dim=20).to(device)\n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Train\n",
    "    model = train_vae(model, train_loader, epochs=10, device=device)\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_results(model, test_loader, device)\n",
    "    \n",
    "    print(\"\\n✓ VAE training complete!\")\n",
    "    print(\"  - Check vae_reconstruction.png for reconstructions\")\n",
    "    print(\"  - Check vae_generated.png for generated samples\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
